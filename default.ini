[checkpoints]
resume_checkpoint    =

[training]
tarantella_GPUs      = 1
batch_size           = 128
optimizer            = SGD
lr                   = 0.07
optimizer_kwargs     = {'momentum':0.9}
N_epochs             = 450
milestones_lr_decay  = [200, 350]

[testing]
sampling_temperature = 0.7
average_batch_norm   = FORWARD

[data]
data_dimensions      = (32, 32, 3)
dataset              = CIFAR10

mu_normalize         = [0.5, 0.5, 0.5]
std_normalize        = [0.5, 0.5, 0.5]

[model]
# defaults match what we have finished pytorch trainings for
# (would choose other architecture params eventually)

# resolution ImageNet   224  112   56   28   14    7
# resolution CIFAR       32   16    8    4    2    1
# channels                3   12   48  192  768  3072
# min RF                  1    2    4    8   16   32
global_affine_init   = [1.0, 1.0, 0.8, 0.7]
affine_clamp         = [0.7, 0.7, 0.7, 1.5]
inn_coupling_blocks  = [8,   24,  24,    1]
inn_subnet_channels  = [16,  32,  64, 1024]
