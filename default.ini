[checkpoints]
resume_checkpoint    =

[training]
batch_size           = 128
optimizer            = SGD
lr                   = 0.07
optimizer_kwargs     = {'momentum': 0.9, 'clipnorm': 15.0}
N_epochs             = 450
milestones_lr_decay  = [200, 350]

[testing]
sampling_temperature = 0.7
average_batch_norm   = FORWARD

[data]
data_dimensions      = (32, 32, 3)
dataset              = CIFAR10

mu_normalize         = (0.4914, 0.4822, 0.4465)
std_normalize        = (0.247, 0.243, 0.261)

[model]
# defaults match what we have finished pytorch trainings for
# (would choose other architecture params eventually)

# resolution ImageNet   224  112   56   28   14    7
# resolution CIFAR       32   16    8    4    2    1
# channels                3   12   48  192  768  3072
# min RF                  1    2    4    8   16   32
global_affine_init   = [0.79] * 4
affine_clamp         = [0.7, 0.7, 0.7, 1.0 ]
inn_coupling_blocks  = [8,   16,  16,   12 ]
inn_subnet_channels  = [16,  32,  64,  128 ]
